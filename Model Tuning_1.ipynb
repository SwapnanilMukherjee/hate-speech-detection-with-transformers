{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model Tuning_1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"67a293d57ecb4e8c95bca70573d42833":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bd66e17f980f45aea9a57f9cb6a2f3ca","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_81ada69a28184536abb1402272db6113","IPY_MODEL_c1a062ea38b040dd83d390ca9f884988"]}},"bd66e17f980f45aea9a57f9cb6a2f3ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"81ada69a28184536abb1402272db6113":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_06956090a4f14bca9bf9806cb6f20366","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":501200538,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":501200538,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5fc61213585447659cfea61bfcfa0833"}},"c1a062ea38b040dd83d390ca9f884988":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e9c3f4fbeeb94af8afd6b631865209cb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 501M/501M [00:22&lt;00:00, 22.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8318c840cf6f400383a544358527def5"}},"06956090a4f14bca9bf9806cb6f20366":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5fc61213585447659cfea61bfcfa0833":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9c3f4fbeeb94af8afd6b631865209cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8318c840cf6f400383a544358527def5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"79308b0cca2f42ac88ea8d48544a0c73":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f2429952a00744a28197a621e80803dd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_abfd46498d964ffa9e582760503379d2","IPY_MODEL_8d72fbcc65fd432b98ba2ac3d87cf844"]}},"f2429952a00744a28197a621e80803dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"abfd46498d964ffa9e582760503379d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d435a4c3173e4042beb0b7f108d40fe2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":467042463,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":467042463,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7fb7e46f165443a2acccb4092323f0b5"}},"8d72fbcc65fd432b98ba2ac3d87cf844":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0abb51360acc4ed4812104b8a140c717","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 467M/467M [26:49&lt;00:00, 290kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4394b01f9b24492d85bf486dd4756991"}},"d435a4c3173e4042beb0b7f108d40fe2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7fb7e46f165443a2acccb4092323f0b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0abb51360acc4ed4812104b8a140c717":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4394b01f9b24492d85bf486dd4756991":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"-t9MsBTUKTHP"},"source":["!pip install SentencePiece transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zSAQrf7ZXrg-","executionInfo":{"status":"ok","timestamp":1628657362101,"user_tz":-330,"elapsed":6475,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification\n","from transformers import XLNetTokenizer, XLNetForSequenceClassification\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","\n","import torch\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torch.nn import CrossEntropyLoss\n","\n","import sklearn\n","from sklearn.model_selection import train_test_split, StratifiedKFold"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"6vEdzq8bYUCH","executionInfo":{"status":"ok","timestamp":1628657362106,"user_tz":-330,"elapsed":8,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":["# df3 = pd.read_csv('/tweets_prepared.csv')\n","df2 = pd.read_csv('/reddit_prepared_new.csv')\n","df1 = pd.read_csv('/gab_prepared_new.csv')\n","\n","# only for hasoc\n","# df1 = pd.read_csv('/hasoc_train_emoji_removed.csv')\n","# df2 = pd.read_csv('/hasoc_test_emoji_removed.csv')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"0d2sf_uQkEig","executionInfo":{"status":"ok","timestamp":1628657365499,"user_tz":-330,"elapsed":491,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":["df1.dropna(axis=0, inplace=True)\n","df1.reset_index(drop=True, inplace=True)\n","\n","df2.dropna(axis=0, inplace=True)\n","df2.reset_index(drop=True, inplace=True)\n","\n","# df3.dropna(axis=0, inplace=True)\n","# df3.reset_index(drop=True, inplace=True)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"QgfqnRDYZzuF","colab":{"base_uri":"https://localhost:8080/","height":203},"executionInfo":{"status":"ok","timestamp":1628627384584,"user_tz":-330,"elapsed":31,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}},"outputId":"178907ae-3b8f-4003-b05c-42fff22871ec"},"source":["df1.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Trump was very prescient tonight when he warne...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Zuckerworm backs down again This is the jew wh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>The nigger says Reeeeeeeee Trump be 's Hitler ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>No problem Seem pissy No 100 no people who are...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>What does make a black person black I know so ...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  label\n","0  Trump was very prescient tonight when he warne...      0\n","1  Zuckerworm backs down again This is the jew wh...      0\n","2  The nigger says Reeeeeeeee Trump be 's Hitler ...      1\n","3  No problem Seem pissy No 100 no people who are...      1\n","4  What does make a black person black I know so ...      0"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"TOk64yYyYohb"},"source":["df1.drop(columns={'Unnamed: 0'}, inplace=True)\n","df2.drop(columns={'Unnamed: 0'}, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j2lFic6oZHYm"},"source":["train_text, temp_text, train_label, temp_label = train_test_split(df3['text'], df3['label'], test_size=0.15, shuffle=True, random_state=697, stratify=df3['label'])\n","test_text, val_text, test_label, val_label = train_test_split(temp_text, temp_label, test_size = 0.5, shuffle=True, random_state=741, stratify=temp_label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6-3pm8lOCmFH"},"source":["# only for HASOC data\n","\n","# train_text, train_label = df1['text'], df1['label']\n","# test_text, test_label = df2['text'], df2['label']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BYCKRUsOozFk","executionInfo":{"status":"ok","timestamp":1628657450992,"user_tz":-330,"elapsed":3502,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":[" tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n"," \n"," def create_inputs(text):   \n","    inputs = [tokenizer(str(x), add_special_tokens=True, max_length=, padding='max_length', truncation=True) for x in text ]\n","    # inputs\n","    input_ids = []\n","    attn_masks = []\n","    for input in inputs:\n","        input_ids.append(input['input_ids'])\n","        attn_masks.append(input['attention_mask'])\n","\n","    return torch.tensor(input_ids), torch.tensor(attn_masks)\n","    # print(input_ids)\n","    # print(attn_masks)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"zvX1Tp25tUIi"},"source":["train_inputs, train_masks = create_inputs(train_text)\n","train_labels = torch.tensor(train_label.values)\n","\n","val_inputs, val_masks = create_inputs(val_text)\n","val_labels = torch.tensor(val_label.values)\n","\n","test_inputs, test_masks = create_inputs(test_text)\n","test_labels = torch.tensor(test_label.values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ETUV0jAMVZvw"},"source":["batch_size = 32\n","\n","#preparing train data\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","#preparing validation data\n","validation_data = TensorDataset(val_inputs, val_masks, val_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","\n","#preparing test data\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jif-rS9C9u-T","executionInfo":{"status":"ok","timestamp":1628602095782,"user_tz":-330,"elapsed":15,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}},"outputId":"38cfac43-995e-4453-879e-f16f280ceb6f"},"source":["weights = sklearn.utils.class_weight.compute_class_weight('balanced', np.unique(df3['label']), df3['label'])\n","class_weights = torch.from_numpy(weights)\n","class_weights.to('cuda')\n","class_weights.cuda()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([5.7758, 0.4304, 1.9854], device='cuda:0', dtype=torch.float64)"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bbTeC17jEwFD","executionInfo":{"status":"ok","timestamp":1628602095783,"user_tz":-330,"elapsed":13,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}},"outputId":"0f256d24-8872-460f-eeb4-f6ff4a937235"},"source":["print(weights)\n","print(class_weights)\n","print(np.unique(df3['label']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[5.77575758 0.43044264 1.98541667]\n","tensor([5.7758, 0.4304, 1.9854], dtype=torch.float64)\n","[0 1 2]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SJiA108ipq5W"},"source":["## **Experiment #1: With roberta-base model and 5 epochs** "]},{"cell_type":"code","metadata":{"id":"-JYHdhM0X9C3","executionInfo":{"status":"ok","timestamp":1628657376638,"user_tz":-330,"elapsed":1276,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":["def get_model(num_labels) :\n","    model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=num_labels)\n","    model.cuda()\n","    return model"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"gEcv6J0AWcii","colab":{"base_uri":"https://localhost:8080/","height":170,"referenced_widgets":["67a293d57ecb4e8c95bca70573d42833","bd66e17f980f45aea9a57f9cb6a2f3ca","81ada69a28184536abb1402272db6113","c1a062ea38b040dd83d390ca9f884988","06956090a4f14bca9bf9806cb6f20366","5fc61213585447659cfea61bfcfa0833","e9c3f4fbeeb94af8afd6b631865209cb","8318c840cf6f400383a544358527def5"]},"executionInfo":{"status":"ok","timestamp":1628657417540,"user_tz":-330,"elapsed":37631,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}},"outputId":"0bdabc25-e54d-410b-f789-4a91613548bc"},"source":["model = get_model(num_labels=2)\n","# print(model)"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67a293d57ecb4e8c95bca70573d42833","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9J881otxtqUQ"},"source":["# freezing all transformer layers of the model except classification layer\n","\n","# for param in model.bert.encoder.layer.parameters():\n","#     param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tp_joLtlZx3w"},"source":["# freezing first few transformer layers of the model \n","\n","for param in model.roberta.encoder.layer.parameters():\n","    param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQI2_S_G0S57"},"source":["# freezing all layers of the model except the last hidden layer and the classification layer\n","\n","# for param in model.transformer.layer.parameters():\n","#     param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KgY1CVkMX9Pt","executionInfo":{"status":"ok","timestamp":1628657417544,"user_tz":-330,"elapsed":41,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":["# optimizing all model paramaters with weight decay except bias terms\n","\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.1},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}]"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"lSZsZmlUX9dV"},"source":["optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)\n","# scheduler = get_linear_schedule_with_warmup(optimizer=optimizer,num_warmup_steps=100, num_training_steps=(len(train_text)//32)*1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YJovWOgeTVqS","executionInfo":{"status":"ok","timestamp":1628657417546,"user_tz":-330,"elapsed":38,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":["def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"6SPCcpOzb3ZR","executionInfo":{"status":"ok","timestamp":1628657417546,"user_tz":-330,"elapsed":36,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":["device = 'cuda'"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"6kXY9TPz-JHN"},"source":["loss_fn = CrossEntropyLoss(weight=class_weights.float()).to('cuda')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7l_Ie4dNbZGr","executionInfo":{"status":"ok","timestamp":1628657417547,"user_tz":-330,"elapsed":36,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":["def training( train_dataloader, epochs=5):\n","\n","    train_loss_set = []\n","\n","    # Number of training epochs (authors recommend between 2 and 4)\n","    epochs = epochs\n","\n","    # trange is a tqdm wrapper around the normal python range\n","    for _ in range(epochs):\n","    \n","    \n","        # Training\n","        \n","        # Set our model to training mode (as opposed to evaluation mode)\n","        model.train()\n","        \n","        # Tracking variables\n","        tr_loss = 0\n","        nb_tr_examples, nb_tr_steps = 0, 0\n","        \n","        # Train the df1 for one epoch\n","        for step, batch in enumerate(train_dataloader):\n","            # Add batch to GPU\n","            batch = tuple(t.to(device) for t in batch)\n","            # Unpack the inputs from our df1loader\n","            b_input_ids, b_input_mask, b_labels = batch\n","            # Clear out the gradients (by default they accumulate)\n","            optimizer.zero_grad()\n","            # Forward pass\n","            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","            loss = outputs[0]\n","            logits = outputs[1]\n","            # loss = loss_fn(logits, b_labels)\n","            train_loss_set.append(loss.item())    \n","            # Backward pass\n","            loss.backward()\n","            # Update parameters and take a step using the computed gradient\n","            optimizer.step()\n","            scheduler.step()\n","            \n","            # Update tracking variables\n","            tr_loss += loss.item()\n","            nb_tr_examples += b_input_ids.size(0)\n","            nb_tr_steps += 1\n","\n","        print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"_vbWsZb_bZTK","executionInfo":{"status":"ok","timestamp":1628657417548,"user_tz":-330,"elapsed":36,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":["def evaluation(validation_dataloader):\n","\n","    model.eval()\n","\n","    # Tracking variables \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # Evaluate df1 for one epoch\n","    for batch in validation_dataloader:\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our df1loader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","        with torch.no_grad():\n","        # Forward pass, calculate logit predictions\n","            output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","            logits = output[0]\n","        \n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        \n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n","    return (eval_accuracy/nb_eval_steps)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhUURtfFjRre","executionInfo":{"status":"ok","timestamp":1628657417549,"user_tz":-330,"elapsed":35,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":["def get_f1_score(test_dataloader):\n","\n","    # Prediction on test set\n","\n","    # Put model in evaluation mode\n","    model.eval()\n","\n","    # Tracking variables \n","    predictions , true_labels = [], []\n","\n","    # Predict \n","    for batch in test_dataloader:\n","    # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        # Unpack the inputs from our df1loader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","        with torch.no_grad():\n","            # Forward pass, calculate logit predictions\n","            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","            logits = outputs[0]\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # Store predictions and true labels\n","        predictions.append(logits)\n","        true_labels.append(label_ids)\n","\n","    # calculating f1 score on test set \n","    from sklearn.metrics import f1_score\n","\n","    pred_list = []\n","    labels = []\n","    for i in true_labels:\n","        labels.extend(i)\n","\n","    for i in range(len(predictions)):\n","        pred_list.append(np.argmax(predictions[i], axis=1).flatten())\n","\n","    preds = []\n","    for i in pred_list:\n","        preds.extend(i)\n","\n","    score = f1_score(labels, preds, average='weighted')\n","    print (\"F1 score: {}\".format(score))\n","    return score, labels, preds"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"j_j-Qug7jRli","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628606188876,"user_tz":-330,"elapsed":200613,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}},"outputId":"7b4491fb-4fdf-45e2-aa22-d4c01d7cf49b"},"source":["training(train_dataloader, epochs=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train loss: 0.2944481255817305\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cOGzOqmi43rk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628606206798,"user_tz":-330,"elapsed":17937,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}},"outputId":"8a5f0fb3-5383-406e-c6ce-0258251ef91f"},"source":["np.mean([evaluation(validation_dataloader)*100, evaluation(test_dataloader)*100])\n","\n","# only for hasoc\n","# evaluation(test_dataloader)*100"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Validation Accuracy: 0.8961864406779662\n","Validation Accuracy: 0.8977754237288136\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["89.69809322033899"]},"metadata":{"tags":[]},"execution_count":102}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HRaXmIIAOCJz","executionInfo":{"status":"ok","timestamp":1628606224685,"user_tz":-330,"elapsed":17899,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}},"outputId":"923272be-fb08-42af-8e63-9e080aa84b87"},"source":["test_score, labels, preds= get_f1_score(test_dataloader)\n","valid_score = get_f1_score(validation_dataloader)[0]\n","np.mean([test_score*100, valid_score*100])\n","\n","#only for HASOC\n","# test_score= get_f1_score(test_dataloader)[0]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["F1 score: 0.870098110576582\n","F1 score: 0.8669239549734803\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["86.85110327750311"]},"metadata":{"tags":[]},"execution_count":103}]},{"cell_type":"code","metadata":{"id":"1-BrEHUu6KMc","executionInfo":{"status":"ok","timestamp":1628659610313,"user_tz":-330,"elapsed":519,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":["from sklearn.metrics import classification_report, plot_confusion_matrix\n","def get_report(labels, preds):\n","    report = classification_report(labels, preds)\n","    print(report)\n","\n","# get_report(labels, preds)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"rU_ynth3bgNW"},"source":["# plt.figure(figsize=(15,8))\n","# plt.title(\"Training loss\")\n","# plt.xlabel(\"Batch\")\n","# plt.ylabel(\"Loss\")\n","# plt.plot(train_loss_set) #inside training function; hence not accessible \n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_3LhESi9iN5Y"},"source":["## Cross validation"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YRogddPWiRSw","executionInfo":{"status":"ok","timestamp":1628599121383,"user_tz":-330,"elapsed":819,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}},"outputId":"7d9658bb-0199-4cc2-e0ac-d025f152987a"},"source":["from sklearn.model_selection import StratifiedKFold\n","\n","X = df3['text']\n","y = df3['label']\n","\n","skf = StratifiedKFold(n_splits=5)\n","skf.get_n_splits(X, y) \n","\n","print(skf)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i06hcmlsiT2o","colab":{"base_uri":"https://localhost:8080/","height":371,"referenced_widgets":["79308b0cca2f42ac88ea8d48544a0c73","f2429952a00744a28197a621e80803dd","abfd46498d964ffa9e582760503379d2","8d72fbcc65fd432b98ba2ac3d87cf844","d435a4c3173e4042beb0b7f108d40fe2","7fb7e46f165443a2acccb4092323f0b5","0abb51360acc4ed4812104b8a140c717","4394b01f9b24492d85bf486dd4756991"]},"outputId":"978a3c58-2d62-4212-c248-63cc234dbe43"},"source":["acc_list = []\n","f1_score_list = []\n","\n","for train_index, test_index in skf.split(X, y):\n","#   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n","    train_text, test_text = X[train_index], X[test_index]\n","    train_label, test_label = y[train_index], y[test_index]\n","        \n","    train_inputs, train_masks = create_inputs(train_text)\n","    train_labels = torch.tensor(train_label.values)\n","    \n","    test_inputs, test_masks = create_inputs(test_text)\n","    test_labels = torch.tensor(test_label.values)\n","    \n","    batch_size = 32\n","    \n","    #preparing train data\n","    train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","    train_sampler = RandomSampler(train_data)\n","    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","    \n","    #preparing test data\n","    test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","    test_sampler = RandomSampler(test_data)\n","    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n","    \n","    model = get_model(num_labels=3)\n","    \n","    param_optimizer = list(model.named_parameters())\n","    no_decay = ['bias', 'gamma', 'beta']\n","    optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.1},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}]\n","    \n","    optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)\n","    scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, num_warmup_steps=100, num_training_steps=(len(train_text)//32)*2)\n","    \n","    training(train_dataloader, epochs=2)\n","    \n","    acc = evaluation(test_dataloader)\n","    acc_list.append(acc)\n","    \n","    f1_score = get_f1_score(test_dataloader)[0]\n","    f1_score_list.append(f1_score)\n","    \n","    print(acc, f1_score)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79308b0cca2f42ac88ea8d48544a0c73","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467042463.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["0.9200367647058824 0.9197780865708056\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["0.9151858660130718 0.9163577069620717\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight', 'logits_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"F20AxHYCC5pg"},"source":["print(acc_list, f1_score_list)\n","print(np.mean(acc_list))\n","print(np.mean(f1_score_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ler1ZcD950Q"},"source":["# only for hasoc\n","\n","# hasoc_test_text, hasoc_test_label = df2['text'], df2['label']\n","\n","# hasoc_test_inputs, hasoc_test_masks = create_inputs(hasoc_test_text)\n","# hasoc_test_labels = to)rch.tensor(hasoc_test_label.values)\n","\n","# hasoc_test_data = TensorDataset(hasoc_test_inputs, hasoc_test_masks, hasoc_test_labels)\n","# hasoc_test_sampler = RandomSampler(hasoc_test_data)\n","# hasoc_test_dataloader = DataLoader(hasoc_test_data, sampler=hasoc_test_sampler, batch_size=batch_size)\n","\n","# print('accuracy:', evaluation(hasoc_test_dataloader))\n","# print('f1 score:', get_f1_score(hasoc_test_dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F4CjaJZevsTo"},"source":["# Training on one dataset and testing on another"]},{"cell_type":"code","metadata":{"id":"NoM6zP8hvyb-","executionInfo":{"status":"ok","timestamp":1628657433054,"user_tz":-330,"elapsed":12390,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":["batch_size = 32\n","\n","train_text = df1['text']\n","train_label = df1['label']\n","\n","test_text = df2['text']\n","test_label = df2['label']\n","\n","train_inputs, train_masks = create_inputs(train_text)\n","train_labels = torch.tensor(train_label.values)\n","    \n","#preparing train data\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size) "],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"phz6auS0v1Y2","executionInfo":{"status":"ok","timestamp":1628657468903,"user_tz":-330,"elapsed":11938,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":["test_inputs, test_masks = create_inputs(test_text)\n","test_labels = torch.tensor(test_label.values)\n","\n","#preparing test data\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"QM2v0VuVv3FW","executionInfo":{"status":"ok","timestamp":1628657474239,"user_tz":-330,"elapsed":774,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}}},"source":["optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)\n","scheduler = get_linear_schedule_with_warmup(optimizer=optimizer,num_warmup_steps=50, num_training_steps=(len(train_text)//32)*2)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"gt02PEMcv5MN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628658879794,"user_tz":-330,"elapsed":1404809,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}},"outputId":"bbe49e23-6fc1-4206-f650-85aa501103e9"},"source":["training(train_dataloader, epochs=2)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Train loss: 0.2622342546705127\n","Train loss: 0.18564267825210598\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C07iW_FFv8ff","executionInfo":{"status":"ok","timestamp":1628659560390,"user_tz":-330,"elapsed":680606,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}},"outputId":"0b20ccc8-450a-4575-d914-f0f1f2fc1515"},"source":["print(evaluation(test_dataloader))\n","score, labels, preds = get_f1_score(test_dataloader)\n","print(score)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Validation Accuracy: 0.9114128075253256\n","0.9114128075253256\n","F1 score: 0.9131267503945883\n","0.9131267503945883\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQLxPdMmv-S9","executionInfo":{"status":"ok","timestamp":1628659615030,"user_tz":-330,"elapsed":926,"user":{"displayName":"Swapnanil Mukherjee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgbIwkHxyH3sjogKCnvs5cZsf9rSlkWpO38qexV3Q=s64","userId":"02391758225265600220"}},"outputId":"f7092e06-4101-48b2-b5b8-21f6274451f5"},"source":["get_report(labels, preds)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.96      0.92      0.94     16869\n","           1       0.78      0.87      0.82      5236\n","\n","    accuracy                           0.91     22105\n","   macro avg       0.87      0.90      0.88     22105\n","weighted avg       0.92      0.91      0.91     22105\n","\n"],"name":"stdout"}]}]}